{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be68fa4a-9012-4826-a75d-0416c1844c7c",
   "metadata": {},
   "source": [
    "# 04b - Modelling with retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812e960-3d55-4b1c-a38c-7e189c70cd2b",
   "metadata": {},
   "source": [
    "__Goal__: \n",
    "- Test some linear models (logistic regression, linear SVM) and nonlinear models (SVM with RBF kernel, decision tree, random forest)\n",
    "- We select the best model on \"validation\" metrics, and provide its score on \"test\" metrics.\n",
    "- 1 means \"rain\", 0 means \"no rain\".\n",
    "- Working when raining is prejudical. We want to predict as much true \"rain\" as possible.\n",
    "- High recall means you less often ask the docker to work during a rainy day.  This causes higher management costs.\n",
    "- High precision means you don't ask the docker to stay at home while the weather is good. This causes higher delays in delivery.\n",
    "- The f1-score is a trade-off between precision  and recall.\n",
    "- The `normalize` parameter `{\"true\", \"pred\", \"all\"}` in `confusin_matrix_evaluation()` normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If `None`, confusion matrix will not be normalized.\n",
    "\n",
    "1. Logistic regression\n",
    "2. Linear SVC\n",
    "3. SVC with RBF kernel\n",
    "4. Decision Tree\n",
    "5. Random Forest\n",
    "6. Test metrics consistancy with pikled pipelines and  models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c9d0f-06da-48cc-8389-a991a7ea4ce2",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f14228-7a03-478c-955b-c3455727df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from weather.transformers.skl_transformer_makers import (\n",
    "    FeatureNames,\n",
    "    TargetChoice,\n",
    "    make_dataset_ingestion_transformer,\n",
    "    make_target_creation_transformer,\n",
    "    make_remove_horizonless_rows_transformer, \n",
    "    make_predictors_feature_engineering_transformer,\n",
    ")\n",
    "from weather.data.prep_datasets import (\n",
    "    prepare_binary_classification_tabular_data, \n",
    "    transform_dataset_and_create_target,\n",
    ")\n",
    "from weather.helpers.utils import camel_to_snake\n",
    "from weather.models.skl_train_models import (\n",
    "    score_evaluation,\n",
    "    train_val_score_evaluation, \n",
    "    train_test_score_evaluation,\n",
    "    print_accuracy_results,\n",
    "    confusion_matrix_evaluation,\n",
    "    confusion_matrix_display,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e6102-c19a-4031-b008-2a7ec362f711",
   "metadata": {},
   "source": [
    "### Set the directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e47fa1-30d6-411f-8281-fed699d5d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =  Path.cwd().parent / \"data\"\n",
    "models_dir = Path.cwd().parent / \"models_two_stages\"\n",
    "models_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73004e-6e11-49e5-aab9-6b917c4c8be2",
   "metadata": {},
   "source": [
    "# 1. Prepare the `dataset` for modelization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e823b-30ee-453b-8931-cc304e059ae4",
   "metadata": {},
   "source": [
    "### Select the predictors and set the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61482ed5-956f-4b18-9efa-469a2fcd1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the predictors\n",
    "feature_names = FeatureNames(\n",
    "    numerical=[\n",
    "        \"Temperature\",\n",
    "        \"Humidity\",\n",
    "        \"Wind_speed\",\n",
    "        \"Wind_bearing\",\n",
    "        \"Visibility\",\n",
    "        \"Pressure\",\n",
    "    ],\n",
    "    categorical=[],  # Add or remove \"Weather\", \"Month\" to the predictors\n",
    ")\n",
    "\n",
    "# Set \"Weather\" within 4 hours as target\n",
    "target_name = \"Weather\"\n",
    "horizon = 4\n",
    "target_choice = TargetChoice(target_name, horizon) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14540f18-da50-4d32-b1eb-71515116d2f0",
   "metadata": {},
   "source": [
    "### Set the dataset transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05033867-8cb3-499b-92a3-12d33f0138b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldnames_newnames_dict = {\n",
    "    \"Temperature_C\": \"Temperature\", \n",
    "    \"Apparent_Temperature_C\": \"Apparent_temperature\",\n",
    "    \"Wind_speed_kmph\": \"Wind_speed\",\n",
    "    \"Wind_bearing_degrees\": \"Wind_bearing\",\n",
    "    \"Visibility_km\": \"Visibility\",\n",
    "    \"Pressure_millibars\": \"Pressure\",\n",
    "    \"Weather_conditions\": \"Weather\"}\n",
    "\n",
    "dataset_ingestion_transformer = make_dataset_ingestion_transformer(target_choice, oldnames_newnames_dict)\n",
    "remove_horizonless_rows_transformer = make_remove_horizonless_rows_transformer(target_choice)\n",
    "target_creation_transformer = make_target_creation_transformer(target_choice)                       \n",
    "train_val_predictors_feature_engineering_transformer = make_predictors_feature_engineering_transformer(feature_names, target_choice)\n",
    "train_test_predictors_feature_engineering_transformer = make_predictors_feature_engineering_transformer(feature_names, target_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6299f-c160-4294-95f1-6d919513e5ea",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e868205-9670-4633-b7b3-60e62821b4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_No</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Apparent_Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Weather_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2881</td>\n",
       "      <td>2006-01-01 00:00:00+00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>1.161111</td>\n",
       "      <td>-3.238889</td>\n",
       "      <td>0.85</td>\n",
       "      <td>16.6152</td>\n",
       "      <td>139</td>\n",
       "      <td>9.9015</td>\n",
       "      <td>1016.15</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S_No                  Timestamp                Location  Temperature_C  \\\n",
       "0  2881  2006-01-01 00:00:00+00:00  Port of Turku, Finland       1.161111   \n",
       "\n",
       "   Apparent_Temperature_C  Humidity  Wind_speed_kmph  Wind_bearing_degrees  \\\n",
       "0               -3.238889      0.85          16.6152                   139   \n",
       "\n",
       "   Visibility_km  Pressure_millibars Weather_conditions  \n",
       "0         9.9015             1016.15               rain  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'weather_dataset_raw_development.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394929a-f30d-401c-839d-fb4cf9957c82",
   "metadata": {},
   "source": [
    "### Transform the dataset and split  it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55323804-bf99-4d98-9415-f01fd1e9cc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Three transformers: \"dataset__ingestion_transformer\", \"remove_horizonless_rows_transformer\", \"target_creation_transformer\"\n",
    "transformed_data, created_target = transform_dataset_and_create_target(\n",
    "    df,   \n",
    "    dataset_ingestion_transformer,\n",
    "    remove_horizonless_rows_transformer,\n",
    "    target_creation_transformer,\n",
    ")\n",
    "\n",
    "# Split the dataset\n",
    "dataset = prepare_binary_classification_tabular_data(\n",
    "    transformed_data,\n",
    "    created_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb136ae2-e36a-4d33-bbef-549920aab427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30673, 4382, 8765, 30673, 4382, 8765)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train_x), len(dataset.val_x), len (dataset.test_x), len(dataset.train_y), len(dataset.val_y), len(dataset.test_y)\n",
    "# (30673, 4382, 8765, 30673, 4382, 8765)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a5b01-0365-4b3c-8433-9bfaa2dbaab2",
   "metadata": {},
   "source": [
    "# 2. Model the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc1a49-0084-4a9d-9c6b-e6888b63a74e",
   "metadata": {},
   "source": [
    "### Define candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2e57b0-280d-43b1-9e12-39155acd941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": DecisionTreeClassifier(max_depth=4, random_state=random_state),\n",
    "    },\n",
    "    \"LinearSvc\": {\n",
    "        \"model\": LinearSVC(max_iter=10_000, random_state=0),\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(max_depth=4, random_state=random_state),\n",
    "        #\"param_grid\": {\"model__n_estimators\": [5, 10], \"model__max_depth\": [None, 5, 10]},\n",
    "    },\n",
    "    \"SvcWithRbfKernel\": {\n",
    "        \"model\": SVC(kernel=\"rbf\", gamma=0.7, random_state=0),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c2680-f220-4284-8252-d6e7a64bf39a",
   "metadata": {},
   "source": [
    "### Set metrics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da53fb9c-7f6b-4ea7-b09c-032ce5b34be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = \"all\"  # for confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a9c96-ac8b-4164-a81b-bc46fe55ca09",
   "metadata": {},
   "source": [
    "###  1 -  `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8f2417-d62b-42d7-971b-0242500ef0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainValScore(score_name='f1_score', train=0.94, val=0.936)\n",
      "TrainTestScore(score_name='f1_score', train_val=0.939, test=0.922)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LogisticRegression\"\n",
    "model = models[model_name][\"model\"]\n",
    "score = f1_score\n",
    "model_subdir  = models_dir / camel_to_snake(model_name)\n",
    "model_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Persist first three pipelines\n",
    "joblib.dump(dataset_ingestion_transformer, model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "joblib.dump(remove_horizonless_rows_transformer, model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "joblib.dump(target_creation_transformer, model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "\n",
    "### Train\n",
    "model.fit(train_val_predictors_feature_engineering_transformer.fit_transform(dataset.train_x), dataset.train_y) # apply fit and transform, successively\n",
    "\n",
    "# Evaluate and display metrics on `train` and `val` splits\n",
    "print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Persit \"train_val_...\" pipelines\n",
    "joblib.dump(train_val_predictors_feature_engineering_transformer, model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_val_model.pkl\");\n",
    "\n",
    "# Concatenate the `train` and `val` splits\n",
    "dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "### Retrain \n",
    "model.fit(train_test_predictors_feature_engineering_transformer.fit_transform(dataset.train_val_x), dataset.train_val_y)\n",
    "\n",
    "# Evaluate and display metrics on `train_val` and `test` splits\n",
    "print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Perist \"train_test_...\"  pipelines\n",
    "joblib.dump(train_test_predictors_feature_engineering_transformer, model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_test_model.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e72524-6773-455d-b9c0-5a907950e0a3",
   "metadata": {},
   "source": [
    "### 2 - `LinearSvc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bba4a65-4226-47cb-83ac-8edf4073dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainValScore(score_name='f1_score', train=0.935, val=0.933)\n",
      "TrainTestScore(score_name='f1_score', train_val=0.933, test=0.916)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LinearSvc\"\n",
    "model = models[model_name][\"model\"]\n",
    "score = f1_score\n",
    "model_subdir  = models_dir / camel_to_snake(model_name)\n",
    "model_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Persist first three pipelines\n",
    "joblib.dump(dataset_ingestion_transformer, model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "joblib.dump(remove_horizonless_rows_transformer, model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "joblib.dump(target_creation_transformer, model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "\n",
    "### Train\n",
    "model.fit(train_val_predictors_feature_engineering_transformer.fit_transform(dataset.train_x), dataset.train_y) # apply fit and transform, successively\n",
    "\n",
    "# Evaluate and display metrics on `train` and `val` splits\n",
    "print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Persit \"train_val_...\" pipelines\n",
    "joblib.dump(train_val_predictors_feature_engineering_transformer, model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_val_model.pkl\");\n",
    "\n",
    "# Concatenate the `train` and `val` splits\n",
    "dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "### Retrain \n",
    "model.fit(train_test_predictors_feature_engineering_transformer.fit_transform(dataset.train_val_x), dataset.train_val_y)\n",
    "\n",
    "# Evaluate and display metrics on `train_val` and `test` splits\n",
    "print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Perist \"train_test_...\"  pipelines\n",
    "joblib.dump(train_test_predictors_feature_engineering_transformer, model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_test_model.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f03125-74b6-4ce9-bb1c-c47049827932",
   "metadata": {},
   "source": [
    "### 3 - `SvcWithRbfKernel` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f339563-458c-4632-a152-be2c851bf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"SvcWithRbfKernel\"\n",
    "# model = models[model_name][\"model\"]\n",
    "# score = f1_score\n",
    "# model_subdir  = models_dir / camel_to_snake(model_name)\n",
    "# model_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Persist first three pipelines\n",
    "# joblib.dump(dataset_ingestion_transformer, model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "# joblib.dump(remove_horizonless_rows_transformer, model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "# joblib.dump(target_creation_transformer, model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "\n",
    "# ### Train\n",
    "# model.fit(train_val_predictors_feature_engineering_transformer.fit_transform(dataset.train_x), dataset.train_y) # apply fit and transform, successively\n",
    "\n",
    "# # Evaluate and display metrics on `train` and `val` splits\n",
    "# print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# # Persit \"train_val_...\" pipelines\n",
    "# joblib.dump(train_val_predictors_feature_engineering_transformer, model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "# joblib.dump(model, model_subdir / \"train_val_model.pkl\");\n",
    "\n",
    "# # Concatenate the `train` and `val` splits\n",
    "# dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "# ### Retrain \n",
    "# model.fit(train_test_predictors_feature_engineering_transformer.fit_transform(dataset.train_val_x), dataset.train_val_y)\n",
    "\n",
    "# # Evaluate and display metrics on `train_val` and `test` splits\n",
    "# print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# # Perist \"train_test_...\"  pipelines\n",
    "# joblib.dump(train_test_predictors_feature_engineering_transformer, model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "# joblib.dump(model, model_subdir / \"train_test_model.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb1229-ee03-4575-91fa-d016ddaa795c",
   "metadata": {},
   "source": [
    "### 4 - `DecisionTree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f9c9524-b98a-4eec-806f-420b31039710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainValScore(score_name='f1_score', train=0.951, val=0.933)\n",
      "TrainTestScore(score_name='f1_score', train_val=0.952, test=0.948)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DecisionTree\"\n",
    "model = models[model_name][\"model\"]\n",
    "score = f1_score\n",
    "model_subdir  = models_dir / camel_to_snake(model_name)\n",
    "model_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Persist first three pipelines\n",
    "joblib.dump(dataset_ingestion_transformer, model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "joblib.dump(remove_horizonless_rows_transformer, model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "joblib.dump(target_creation_transformer, model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "\n",
    "### Train\n",
    "model.fit(train_val_predictors_feature_engineering_transformer.fit_transform(dataset.train_x), dataset.train_y) # apply fit and transform, successively\n",
    "\n",
    "# Evaluate and display metrics on `train` and `val` splits\n",
    "print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Persit \"train_val_...\" pipelines\n",
    "joblib.dump(train_val_predictors_feature_engineering_transformer, model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_val_model.pkl\");\n",
    "\n",
    "# Concatenate the `train` and `val` splits\n",
    "dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "### Retrain \n",
    "model.fit(train_test_predictors_feature_engineering_transformer.fit_transform(dataset.train_val_x), dataset.train_val_y)\n",
    "\n",
    "# Evaluate and display metrics on `train_val` and `test` splits\n",
    "print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Perist \"train_test_...\"  pipelines\n",
    "joblib.dump(train_test_predictors_feature_engineering_transformer, model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_test_model.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a70d77-c4fd-4045-b9fd-8e36c2b6905c",
   "metadata": {},
   "source": [
    "### 5 - `RandomForest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefbfca8-5369-413e-a96a-321b5ea5b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainValScore(score_name='f1_score', train=0.952, val=0.942)\n",
      "TrainTestScore(score_name='f1_score', train_val=0.952, test=0.952)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"RandomForest\"\n",
    "model = models[model_name][\"model\"]\n",
    "score = f1_score\n",
    "model_subdir  = models_dir / camel_to_snake(model_name)\n",
    "model_subdir.mkdir(exist_ok=True)\n",
    "\n",
    "# Persist first three pipelines\n",
    "joblib.dump(dataset_ingestion_transformer, model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "joblib.dump(remove_horizonless_rows_transformer, model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "joblib.dump(target_creation_transformer, model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "\n",
    "### Train\n",
    "model.fit(train_val_predictors_feature_engineering_transformer.fit_transform(dataset.train_x), dataset.train_y) # apply fit and transform, successively\n",
    "\n",
    "# Evaluate and display metrics on `train` and `val` splits\n",
    "print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Persit \"train_val_...\" pipelines\n",
    "joblib.dump(train_val_predictors_feature_engineering_transformer, model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_val_model.pkl\");\n",
    "\n",
    "# Concatenate the `train` and `val` splits\n",
    "dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "### Retrain \n",
    "model.fit(train_test_predictors_feature_engineering_transformer.fit_transform(dataset.train_val_x), dataset.train_val_y)\n",
    "\n",
    "# Evaluate and display metrics on `train_val` and `test` splits\n",
    "print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, model, dataset))\n",
    "\n",
    "# Perist \"train_test_...\"  pipelines\n",
    "joblib.dump(train_test_predictors_feature_engineering_transformer, model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "joblib.dump(model, model_subdir / \"train_test_model.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0054456-6ce2-4d74-96d1-1b8d3c42bd70",
   "metadata": {},
   "source": [
    "### 6. Test metrics consistancy with pikled pipelines and  models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88072f74-09f9-4b7e-95ea-0b58fd92a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transformer = joblib.load(model_subdir / \"dataset_eng_pipeline.pkl\")\n",
    "remove_horizonless_rows_transformer = joblib.load(model_subdir / \"remove_horizonless_rows_eng_pipeline.pkl\")\n",
    "target_creation_transformer = joblib.load(model_subdir / \"target_creation_eng_pipeline.pkl\")\n",
    "train_val_predictors_feature_engineering_transformer =joblib.load(model_subdir / \"train_val_predictors_feature_eng_pipeline.pkl\")\n",
    "train_test_predictors_feature_engineering_transformer =joblib.load(model_subdir / \"train_test_predictors_feature_eng_pipeline.pkl\")\n",
    "train_val_model = joblib.load(model_subdir / \"train_val_model.pkl\")\n",
    "train_test_model = joblib.load(model_subdir / \"train_test_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972aa2ed-dd36-498f-822d-b9ba14b3092f",
   "metadata": {},
   "source": [
    "### Transform the dataset and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cd37c0f-2bc3-47e1-9353-ffc2825bb0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "transformed_data, created_target = transform_dataset_and_create_target(\n",
    "    df,   \n",
    "    dataset_ingestion_transformer,\n",
    "    remove_horizonless_rows_transformer,\n",
    "    target_creation_transformer,\n",
    ")\n",
    "\n",
    "# Split\n",
    "dataset = prepare_binary_classification_tabular_data(\n",
    "    transformed_data,\n",
    "    created_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f769fc-8966-4e3f-8427-8eaeb10b43ba",
   "metadata": {},
   "source": [
    "### Display `f1-score`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bba2a32e-d6a4-4244-88a0-d17e9bc9079c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainValScore(score_name='f1_score', train=0.952, val=0.942)\n",
      "TrainTestScore(score_name='f1_score', train_val=0.952, test=0.952)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and display metrics on `train` and `val` splits\n",
    "print(train_val_score_evaluation(score, train_val_predictors_feature_engineering_transformer, train_val_model, dataset))\n",
    "\n",
    "# Concatenate the `train` and `val` splits\n",
    "dataset.concatenate_train_and_val_splits()\n",
    "\n",
    "# Evaluate and display metrics on `train_val` and `test` splits\n",
    "print(train_test_score_evaluation(score, train_test_predictors_feature_engineering_transformer, train_test_model, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba62da8-0874-409f-bf38-d8128b02ce49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
