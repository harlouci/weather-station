{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - `Deepchecks` for `Data validation` and `Model validation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Goal__:\n",
    "1. Data validation with an `html` output\n",
    "2. Data validation with a `boolean` output\n",
    "3. Model validation with an `html` output\n",
    "4. Model validation with a `boolean` output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from deepchecks.tabular import Dataset as DeepChecksDataset\n",
    "from deepchecks.tabular.suites import data_integrity\n",
    "from deepchecks.tabular.suites import model_evaluation\n",
    "\n",
    "from weather.data.prep_datasets import (\n",
    "    Dataset,\n",
    "    transform_dataset_and_create_target,\n",
    "    prepare_binary_classification_tabular_data,\n",
    ")\n",
    "from weather.transformers.skl_transformer_makers import (\n",
    "    make_dataset_ingestion_transformer,\n",
    "    make_predictors_feature_engineering_transformer,\n",
    "    make_remove_horizonless_rows_transformer,\n",
    "    make_target_creation_transformer,\n",
    ")\n",
    "from weather.pipelines.definitions import (\n",
    "    feature_names,\n",
    "    metric,\n",
    "    oldnames_newnames_dict,\n",
    "    target_choice,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "deepchecks_dir = Path('./deepchecks')\n",
    "deepchecks_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = Path.cwd().parent / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "model_subdir  = models_dir / \"random_forest\"\n",
    "model_subdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_ingested_data(ingested_df, feature_names, target_choice):\n",
    "    \"\"\"Run the data integrity suite on `ingested_df`. Return True if all tests pass, False otherwise.\"\"\"\n",
    "    # Populate Dataset parameters\n",
    "    features = feature_names.numerical + feature_names.categorical + [target_choice.input_name]\n",
    "    cat_features = [target_choice.input_name]\n",
    "    # Convert ingested_df into a deepchecks Dataset instance\n",
    "    ds = DeepChecksDataset(ingested_df, features = features, cat_features = cat_features)\n",
    "    # Run integrity suite \n",
    "    integrity_suite = data_integrity()\n",
    "    results = integrity_suite.run(ds)\n",
    "    return results.passed()\n",
    "\n",
    "def validate_model(dataset, trained_model, trained_predictors_feature_engineering_transformer, excluded_check=5):\n",
    "    \"\"\"Run the validation suite minus `WeekSegmentPerformance` on `dataset`. Return True if all tests pass, False otherwise.\"\"\"\n",
    "    # Populate train_ds\n",
    "    X_train = trained_predictors_feature_engineering_transformer.transform(dataset.train_x)\n",
    "    y_train = dataset.train_y\n",
    "    train_ds = DeepChecksDataset(X_train, label=y_train, cat_features=[])\n",
    "    # Populate test_ds\n",
    "    X_test = trained_predictors_feature_engineering_transformer.transform(dataset.test_x)\n",
    "    y_test = dataset.test_y\n",
    "    test_ds = DeepChecksDataset(X_test, label=y_test, cat_features=[])\n",
    "    # Run model validation suite \n",
    "    evaluation_suite = model_evaluation()\n",
    "    results = evaluation_suite.remove(excluded_check).run(train_ds, test_ds, trained_model)\n",
    "    return results.passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data validation with an `html` output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43848 entries, 0 to 43847\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   S_No                    43848 non-null  int64  \n",
      " 1   Timestamp               43848 non-null  object \n",
      " 2   Location                43848 non-null  object \n",
      " 3   Temperature_C           43848 non-null  float64\n",
      " 4   Apparent_Temperature_C  43848 non-null  float64\n",
      " 5   Humidity                43848 non-null  float64\n",
      " 6   Wind_speed_kmph         43848 non-null  float64\n",
      " 7   Wind_bearing_degrees    43848 non-null  int64  \n",
      " 8   Visibility_km           43848 non-null  float64\n",
      " 9   Pressure_millibars      43848 non-null  float64\n",
      " 10  Weather_conditions      43843 non-null  object \n",
      "dtypes: float64(6), int64(2), object(3)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = 'weather_dataset_raw_development.csv'\n",
    "df = pd.read_csv(data_dir / csv_file_name)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Wind_bearing</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00+00:00</th>\n",
       "      <td>1.161111</td>\n",
       "      <td>0.85</td>\n",
       "      <td>16.6152</td>\n",
       "      <td>139</td>\n",
       "      <td>9.9015</td>\n",
       "      <td>1016.15</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Temperature  Humidity  Wind_speed  Wind_bearing  \\\n",
       "2006-01-01 00:00:00+00:00     1.161111      0.85     16.6152           139   \n",
       "\n",
       "                           Visibility  Pressure Weather  \n",
       "2006-01-01 00:00:00+00:00      9.9015   1016.15    rain  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ingestion_transformer = make_dataset_ingestion_transformer(target_choice, oldnames_newnames_dict)\n",
    "ingested_df = dataset_ingestion_transformer.transform(df)\n",
    "ingested_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform into a `deepchecks.Dataset` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Temperature\", \"Humidity\", \"Wind_speed\",  \"Wind_bearing\", \"Visibility\", \"Pressure\", \"Weather\"]\n",
    "cat_features = [\"Weather\"] # must be a subset of features\n",
    "\n",
    "ds_name=\"ingested_data\" \n",
    "ds = DeepChecksDataset(\n",
    "    ingested_df,\n",
    "    features=features,\n",
    "    cat_features=cat_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data integrity suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Integrity Suite: [\n",
       "\t0: IsSingleValue\n",
       "\t\tConditions:\n",
       "\t\t\t0: Does not contain only a single value\n",
       "\t1: SpecialCharacters\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ratio of samples containing solely special character is less or equal to 0.1%\n",
       "\t2: MixedNulls\n",
       "\t\tConditions:\n",
       "\t\t\t0: Number of different null types is less or equal to 1\n",
       "\t3: MixedDataTypes\n",
       "\t\tConditions:\n",
       "\t\t\t0: Rare data types in column are either more than 10% or less than 1% of the data\n",
       "\t4: StringMismatch\n",
       "\t\tConditions:\n",
       "\t\t\t0: No string variants\n",
       "\t5: DataDuplicates\n",
       "\t\tConditions:\n",
       "\t\t\t0: Duplicate data ratio is less or equal to 5%\n",
       "\t6: StringLengthOutOfBounds\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ratio of string length outliers is less or equal to 0%\n",
       "\t7: ConflictingLabels\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ambiguous sample ratio is less or equal to 0%\n",
       "\t8: OutlierSampleDetection\n",
       "\t9: FeatureLabelCorrelation(ppscore_params={}, random_state=42)\n",
       "\t\tConditions:\n",
       "\t\t\t0: Features' Predictive Power Score is less than 0.8\n",
       "\t10: FeatureFeatureCorrelation\n",
       "\t\tConditions:\n",
       "\t\t\t0: Not more than 0 pairs are correlated above 0.9\n",
       "\t11: IdentifierLabelCorrelation(ppscore_params={})\n",
       "\t\tConditions:\n",
       "\t\t\t0: Identifier columns PPS is less or equal to 0\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_suite = data_integrity()\n",
    "integrity_suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepchecks\\ingested_data\n"
     ]
    }
   ],
   "source": [
    "deepchecks_subdir = deepchecks_dir / ds_name\n",
    "deepchecks_subdir.mkdir(exist_ok=True)\n",
    "print(deepchecks_subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = integrity_suite.run(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of `results`:\n",
      "\n",
      "extra_info\n",
      "failures\n",
      "from_json\n",
      "get_not_passed_checks\n",
      "get_not_ran_checks\n",
      "get_passed_checks\n",
      "html_serializer\n",
      "ipython_serializer\n",
      "name\n",
      "passed\n",
      "results\n",
      "results_with_conditions\n",
      "results_with_display\n",
      "results_without_conditions\n",
      "results_without_display\n",
      "save_as_cml_markdown\n",
      "save_as_html\n",
      "select_results\n",
      "show\n",
      "show_in_iframe\n",
      "show_in_window\n",
      "show_not_interactive\n",
      "to_json\n",
      "to_wandb\n",
      "to_widget\n",
      "widget_serializer\n"
     ]
    }
   ],
   "source": [
    "results_attributes = \"\\n\".join([attributes for attributes in dir(results) if not attributes.startswith(\"_\")])\n",
    "print(f\"Attributes of `results`:\\n\\n{results_attributes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.save_as_html(\"integrity_suite_output.html\")\n",
    "#shutil.move(\"integrity_suite_output.html\", deepchecks_subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data validation with a boolean output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data and ingest it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed</th>\n",
       "      <th>Wind_bearing</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00+00:00</th>\n",
       "      <td>1.161111</td>\n",
       "      <td>0.85</td>\n",
       "      <td>16.6152</td>\n",
       "      <td>139</td>\n",
       "      <td>9.9015</td>\n",
       "      <td>1016.15</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Temperature  Humidity  Wind_speed  Wind_bearing  \\\n",
       "2006-01-01 00:00:00+00:00     1.161111      0.85     16.6152           139   \n",
       "\n",
       "                           Visibility  Pressure Weather  \n",
       "2006-01-01 00:00:00+00:00      9.9015   1016.15    rain  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_name = 'weather_dataset_raw_development.csv'\n",
    "df = pd.read_csv(data_dir / csv_file_name)\n",
    "dataset_ingestion_transformer = make_dataset_ingestion_transformer(target_choice, oldnames_newnames_dict)\n",
    "ingested_df = dataset_ingestion_transformer.transform(df)\n",
    "ingested_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data integrity suite passed: True\n"
     ]
    }
   ],
   "source": [
    "data_integrity_suite_passed = validate_ingested_data(ingested_df, feature_names, target_choice)\n",
    "print(f\"The data integrity suite passed: {data_integrity_suite_passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model validation with an `html` output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data, ingest, transform and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \n",
    "csv_file_name = 'weather_dataset_raw_development.csv'\n",
    "df = pd.read_csv(data_dir / csv_file_name)\n",
    "\n",
    "# Ingest and transform\n",
    "remove_horizonless_rows_transformer = make_remove_horizonless_rows_transformer(target_choice)\n",
    "target_creation_transformer = make_target_creation_transformer(target_choice)\n",
    "transformed_data, created_target = transform_dataset_and_create_target(\n",
    "    df,   \n",
    "    dataset_ingestion_transformer,\n",
    "    remove_horizonless_rows_transformer,\n",
    "    target_creation_transformer,\n",
    ")\n",
    "\n",
    "# Split\n",
    "dataset = prepare_binary_classification_tabular_data(\n",
    "    transformed_data,\n",
    "    created_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model and fitted transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = joblib.load(model_subdir / \"model.pkl\")\n",
    "trained_predictors_feature_engineering_transformer = joblib.load(model_subdir / \"predictors_feature_eng_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate  `train_ds` and `train_val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate train_ds\n",
    "X_train = trained_predictors_feature_engineering_transformer.transform(dataset.train_x)\n",
    "y_train = dataset.train_y\n",
    "train_ds = DeepChecksDataset(X_train, label=y_train, cat_features=[])\n",
    "\n",
    "# Populate test_ds\n",
    "X_test = trained_predictors_feature_engineering_transformer.transform(dataset.test_x)\n",
    "y_test = dataset.test_y\n",
    "test_ds = DeepChecksDataset(X_test, label=y_test, cat_features=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model evaluation suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Evaluation Suite: [\n",
       "\t0: TrainTestPerformance\n",
       "\t\tConditions:\n",
       "\t\t\t0: Train-Test scores relative degradation is less than 0.1\n",
       "\t1: RocReport\n",
       "\t\tConditions:\n",
       "\t\t\t0: AUC score for all the classes is greater than 0.7\n",
       "\t2: ConfusionMatrixReport\n",
       "\t3: PredictionDrift\n",
       "\t\tConditions:\n",
       "\t\t\t0: Prediction drift score < 0.15\n",
       "\t4: SimpleModelComparison\n",
       "\t\tConditions:\n",
       "\t\t\t0: Model performance gain over simple model is greater than 10%\n",
       "\t5: WeakSegmentsPerformance(n_to_show=5)\n",
       "\t\tConditions:\n",
       "\t\t\t0: The relative performance of weakest segment is greater than 80% of average model performance.\n",
       "\t6: CalibrationScore\n",
       "\t7: RegressionErrorDistribution\n",
       "\t\tConditions:\n",
       "\t\t\t0: Kurtosis value higher than -0.1\n",
       "\t\t\t1: Systematic error ratio lower than 0.01\n",
       "\t8: UnusedFeatures\n",
       "\t\tConditions:\n",
       "\t\t\t0: Number of high variance unused features is less or equal to 5\n",
       "\t9: BoostingOverfit\n",
       "\t\tConditions:\n",
       "\t\t\t0: Test score over iterations is less than 5% from the best score\n",
       "\t10: ModelInferenceTime\n",
       "\t\tConditions:\n",
       "\t\t\t0: Average model inference time for one sample is less than 0.001\n",
       "]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_suite = model_evaluation()\n",
    "evaluation_suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = evaluation_suite.run(train_ds, test_ds, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of `results`:\n",
      "\n",
      "extra_info\n",
      "failures\n",
      "from_json\n",
      "get_not_passed_checks\n",
      "get_not_ran_checks\n",
      "get_passed_checks\n",
      "html_serializer\n",
      "ipython_serializer\n",
      "name\n",
      "passed\n",
      "results\n",
      "results_with_conditions\n",
      "results_with_display\n",
      "results_without_conditions\n",
      "results_without_display\n",
      "save_as_cml_markdown\n",
      "save_as_html\n",
      "select_results\n",
      "show\n",
      "show_in_iframe\n",
      "show_in_window\n",
      "show_not_interactive\n",
      "to_json\n",
      "to_wandb\n",
      "to_widget\n",
      "widget_serializer\n"
     ]
    }
   ],
   "source": [
    "results_attributes = \"\\n\".join([attributes for attributes in dir(results) if not attributes.startswith(\"_\")])\n",
    "print(f\"Attributes of `results`:\\n\\n{results_attributes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Weak Segments Performance - Train Dataset: {'weak_segments_list':   Accuracy Score          Feature1  \\\n",
       " 0       0.650619  num__Temperature   \n",
       " 5       0.865618     num__Pressure   \n",
       " \n",
       "                                Feature1 Range Feature2 Feature2 Range  \\\n",
       " 0  (-1.4711160063743591, -1.1533008217811584)                    None   \n",
       " 5                   (1.0168207883834839, inf)                    None   \n",
       " \n",
       "   % of Data                                 Samples in Segment  \n",
       " 0      7.27  [2008-11-28 08:00:00+00:00, 2009-02-13 03:00:0...  \n",
       " 5     13.99  [2008-01-23 06:00:00+00:00, 2006-12-28 09:00:0...  , 'avg_score': 0.915},\n",
       " Weak Segments Performance - Test Dataset: {'weak_segments_list':   Accuracy Score          Feature1                             Feature1 Range  \\\n",
       " 0       0.695332  num__Temperature  (-1.518832504749298, -1.1656718254089355)   \n",
       " \n",
       "   Feature2 Feature2 Range % of Data  \\\n",
       " 0                    None      9.29   \n",
       " \n",
       "                                   Samples in Segment  \n",
       " 0  [2010-01-13 21:00:00+00:00, 2010-02-14 03:00:0...  , 'avg_score': 0.926}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_not_passed_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model validation with a `boolean` output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data, ingest, transform and split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \n",
    "csv_file_name = 'weather_dataset_raw_development.csv'\n",
    "df = pd.read_csv(data_dir / csv_file_name)\n",
    "\n",
    "# Ingest and transform\n",
    "remove_horizonless_rows_transformer = make_remove_horizonless_rows_transformer(target_choice)\n",
    "target_creation_transformer = make_target_creation_transformer(target_choice)\n",
    "transformed_data, created_target = transform_dataset_and_create_target(\n",
    "    df,   \n",
    "    dataset_ingestion_transformer,\n",
    "    remove_horizonless_rows_transformer,\n",
    "    target_creation_transformer,\n",
    ")\n",
    "\n",
    "# Split\n",
    "dataset = prepare_binary_classification_tabular_data(\n",
    "    transformed_data,\n",
    "    created_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model and fitted transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = joblib.load(model_subdir / \"model.pkl\")\n",
    "trained_predictors_feature_engineering_transformer = joblib.load(model_subdir / \"predictors_feature_eng_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        progress {\n",
       "            -webkit-appearance: none;\n",
       "            border: none;\n",
       "            border-radius: 3px;\n",
       "            width: 300px;\n",
       "            height: 20px;\n",
       "            vertical-align: middle;\n",
       "            margin-right: 10px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-bar {\n",
       "            border-radius: 3px;\n",
       "            background-color: aliceblue;\n",
       "        }\n",
       "        progress::-webkit-progress-value {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "        progress::-moz-progress-bar {\n",
       "            background-color: #9d60fb;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model validation suite minus 'WeekSegmentPerformance' passed: True\n"
     ]
    }
   ],
   "source": [
    "model_validation_suite_passed = validate_model(dataset, trained_model, trained_predictors_feature_engineering_transformer)\n",
    "print(f\"The model validation suite minus 'WeekSegmentPerformance' passed: {model_validation_suite_passed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
